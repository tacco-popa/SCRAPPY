# ğŸ“Š SCRAPPY â€” Smart Web Scraping Toolkit

> **Easily scrape data from any paginated website, auto-detect tables, and export your results â€” deployable instantly on Vercel.**

**Live Demo:** [https://scrappy-git-main-tbzs-projects-722eb033.vercel.app/](https://scrappy-git-main-tbzs-projects-722eb033.vercel.app/)

SCRAPPY is a lightweight, **Vercel-ready web scraping solution** built with **FastAPI** and **BeautifulSoup**.  
It features a clean static HTML frontend and a serverless backend, perfect for fast deployments and scalable scraping tasks.

---

## ğŸš€ Features

- ğŸ” **Smart Table Detection** â€“ Automatically finds headers and rows.  
- ğŸ“„ **Pagination Support** â€“ Works with `{page}` placeholders or query params like `?page=2`.  
- âš¡ **Concurrent Scraping** â€“ Fetch multiple pages in parallel for speed.  
- ğŸ“Š **Flexible Output** â€“ Download results as CSV or JSON.  
- â˜ï¸ **Vercel-Ready** â€“ Deploy in one click, fully serverless.  
- ğŸ–¥ï¸ **Simple UI** â€“ Paste a URL and start scraping right away.

---

## ğŸ“‚ Project Structure

```
SCRAPPY/
â”‚
â”œâ”€â”€ api/               # Serverless backend
â”‚   â””â”€â”€ scrape.py      # FastAPI scraping function
â”‚
â”œâ”€â”€ index.html         # Static frontend UI
â”œâ”€â”€ main.py            # Entrypoint for Vercel (serves index + routes API)
â”œâ”€â”€ requirements.txt   # Python dependencies
â””â”€â”€ README.md          # This file
```

---

## ğŸ› ï¸ Getting Started

### 1. Clone the Repo
```bash
git clone https://github.com/your-username/SCRAPPY.git
cd SCRAPPY
```

### 2. Install Dependencies
Make sure you have **Python 3.11+** installed.

```bash
pip install -r requirements.txt
```

### 3. Run Locally
Start the FastAPI server:
```bash
uvicorn api.scrape:app --reload
```

Visit:
- **Frontend:** [http://127.0.0.1:8000/](http://127.0.0.1:8000/)
- **API Endpoint:** [http://127.0.0.1:8000/api/scrape](http://127.0.0.1:8000/api/scrape)

---

## ğŸŒ Deploying to Vercel

### **Option A â€” Simplest Setup**
Deploy directly:
1. Push your code to GitHub.
2. Go to [Vercel](https://vercel.com/).
3. Import your repo.
4. Vercel automatically detects:
   - `index.html` â†’ static site root
   - `api/` â†’ Python serverless function
5. Click **Deploy** ğŸš€

**Live version:** [https://scrappy-git-main-tbzs-projects-722eb033.vercel.app/](https://scrappy-git-main-tbzs-projects-722eb033.vercel.app/)

---

### **Option B â€” With FastAPI Preset**
If Vercel needs an explicit app:
- Keep `main.py` at the root with this content:
  ```python
  from api.scrape import app
  from fastapi.responses import HTMLResponse
  from pathlib import Path

  @app.get("/", response_class=HTMLResponse)
  def home():
      return Path("index.html").read_text(encoding="utf-8")
  ```
- Then redeploy.

---

## ğŸ“¡ Example API Payload

You can test the backend directly by POSTing JSON to `/api/scrape`.

Example request:
```json
{
  "template": "https://example.com/products?page={page}",
  "css_selector": "table",
  "table_index": 0,
  "header_strategy": "auto",
  "start_page": 1,
  "end_page": 5,
  "concurrency": 10,
  "format": "csv"
}
```

Using **cURL**:
```bash
curl -X POST https://scrappy-git-main-tbzs-projects-722eb033.vercel.app/api/scrape -H "Content-Type: application/json" -d '{
  "template": "https://example.com/products?page={page}",
  "start_page": 1,
  "end_page": 3
}'
```

---

## ğŸ“¸ Screenshots


![Screenshot_28-9-2025_13257_scrappy-git-main-tbzs-projects-722eb033 vercel app](https://github.com/user-attachments/assets/7e55402f-844a-4086-8f29-114cb02f40e7)



---

## ğŸ¤ Contributing
Conributions are welcomed 
To contribute:
1. Fork this repo
2. Create a feature branch (`git checkout -b feature-name`)
3. Commit your changes
4. Push and open a pull request

---

## ğŸ“ License
This project is open source and available under the **MIT License**.
